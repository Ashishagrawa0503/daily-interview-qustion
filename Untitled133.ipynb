{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCPIkuv/J+6UaGOJVVfim5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishagrawa0503/daily-interview-qustion/blob/main/Untitled133.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **activation functions**"
      ],
      "metadata": {
        "id": "OtGXmh72fNCf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rmhUka2BfLPo"
      },
      "outputs": [],
      "source": [
        "# 1.linear activation function\n",
        "#jo be value aaye ge usko he return kr defa\n",
        "def linear_activation(x):\n",
        "  return x\n",
        "nn.activation=linear_activation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "#trashold function\n",
        "#  {0 if 0>x}\n",
        "# {1 if x>=0}\n",
        "def trashold_activation(x,threshold=0.5,value=0):#x ya thras hold ke value kuch be rakh sktea hai\n",
        "  return 1 if x>=threshold else value\n",
        "print (trashold_activation(0.4))\n",
        "nn.activation=trashold_activation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylJDPcERil9p",
        "outputId": "1b39c3e2-f573-4625-f6ea-8daa21489717"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sigmoid activation\n",
        "def sigmoid(x):\n",
        "  return (1/(1+torch.exp(-x)))"
      ],
      "metadata": {
        "id": "EvcGGsQDkn1M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #tanh activation function\n",
        "\n",
        "def tanh_activation(x):\n",
        "    return (torch.exp(x)-torch.exp(-x)/torch.exp(x)+torch.exp(-x))\n",
        "\n"
      ],
      "metadata": {
        "id": "k-_iKGer7Df5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax activation function\n",
        "\n",
        "def softmax_function(x):\n",
        "  exp_x= torch.exp(x)\n",
        "  return exp_x/torch.sum(exp_x,dim=-1,keepdim=True)\n",
        "\n",
        "\n",
        "  softmax = nn.softmax(dim=-1)# last dimnsion\n",
        ""
      ],
      "metadata": {
        "id": "mIdTa1dV_OLz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# relu activation function\n",
        "def relu_activation(x):\n",
        "  return torch.maximum(x,torch.tensor(0,dtype=x.dtype))\n",
        ""
      ],
      "metadata": {
        "id": "zIXaUyvcP0gq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#leaky relu activation function\n",
        "\n",
        "def leaky_relu(x,negative_slop=0.01):\n",
        "  return torch.where(x>0 ,x,negative_slop*x)"
      ],
      "metadata": {
        "id": "8jxdfW1wSS7h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paramatric relu activation function\n",
        "def paramatric_relu(x,a):\n",
        "  return torch.where(x>0 ,x ,a*x ) #where a is learning parameter\n",
        ""
      ],
      "metadata": {
        "id": "dc1h5RRYUUHj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exponential relu activation function\n",
        "def expo_relu(x,a=0.1):\n",
        "  return torch.where(x>0 ,x , a(torch.exp(x)-1))"
      ],
      "metadata": {
        "id": "yr8XoyWVXUBb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selu activation function\n",
        "def selu_activation(x,a=1.6733,b=1.0507):\n",
        "  return b*torch.where(x>0,x , a(torch.exp(x)-1))"
      ],
      "metadata": {
        "id": "apcEbdpBaMhg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# swish activation function\n",
        "def swish_activation(x,beta=1.0):\n",
        "  return x*(torch.sigmoid(beta*x))\n"
      ],
      "metadata": {
        "id": "B5ivHC1BcKLa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# softplus activation function\n",
        "def softplus(x,beta =1.0,threshold=20.0):\n",
        "  return torch.where(beta*x > threshold ,x ,(1/beta) * torch.log(1+ torch.ep(beta*x)))"
      ],
      "metadata": {
        "id": "Z1gi61HOdNLf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcjNIhvchX9q"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}