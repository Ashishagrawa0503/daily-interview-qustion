# NAIVE BAYES CLASSIFICATION

import numpy as np
class Naviebayes:
  def fit(self,X,y):
    self.classes=np.unique(y)
    n_features=X.shape[1]
    n_classes=len(self.classes)

    self.mean= np.zeros((n_classes,n_features))
    self.var= np.zeros((n_classes,n_features))
    self.priors=np.zeros(n_classes) 

    for idx,c in enumerate(self.classes):
      X_c=X[y == c]#x main jis jis idx number ke labels(y) = c(maana de gai value exmple 0 hai) waha waha true ho jayega baki false ho jayega
      self.mean[idx,:]=X_c.mean(axis=0) # column wise mean
      self.var[idx,:]=X_c.var(axis=0)
      self.priors[idx]=X_c.shape[0]/float(X.shape[0])

  def predict(self,X):
    return np.array([self._predict(x) for x in X])

  def _predict(self,x):
    posteriors=[]
    for idx ,c in enumerate(self.classes):
      prior=np.log(self.priors[idx]) # log(P(class))
      class_conditional=np.sum(np.log(self._pdf(idx,x))) # log(P(x|class))
      posterior=prior+class_conditional
      posteriors.append(posterior)
    return self.classes[np.argmax(posteriors)]# subse bade priors wale class
 
 
  def _pdf(self,class_idx,x):
    mean = self.mean[class_idx]
    var = self.var[class_idx]
    numerator=np.exp(-(x-mean)**2/(2*var))
    denominator=np.sqrt(2*np.pi*var)
    return numerator/denominator
