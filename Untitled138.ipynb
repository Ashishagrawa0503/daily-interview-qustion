{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNub+w7l78P505pka1UbFYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishagrawa0503/daily-interview-qustion/blob/main/Untitled138.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# machine learning Unsupervised learning\n",
        "\n",
        "#DBSCAN\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.cluster import DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "X, _ = make_moons(n_samples=300, noise=0.05)\n",
        "db = DBSCAN(eps=0.2, min_samples=5)\n",
        "labels = db.fit_predict(X)\n",
        "\n",
        "\n",
        "#hierarchical clustering\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.cluster.hierarchy as sch\n",
        "X, _ = make_blobs(n_samples=100, centers=3, cluster_std=1.0)\n",
        "model = AgglomerativeClustering(n_clusters=3)\n",
        "labels = model.fit_predict(X)\n",
        "\n",
        "\n",
        "# kmeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6, random_state=0)\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "kmeans.fit(X)\n",
        "labels = kmeans.predict(X)\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UJ0b0Gwv1lwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK9dK3Cti5iQ"
      },
      "outputs": [],
      "source": [
        "#machine learning algorithms supervised learning in classification\n",
        "# NAIVE BIYES ALGORITHM\n",
        "\"\"\"\n",
        "it is use for classification task .it is a probabilistic classifier based on bayes therom. its classifi data inti categories\n",
        "using probability. efficiently handle large datset and high-dimension data set,provied fast simple,accurate classification\n",
        "especially with text data.common case uses- smap ditiction sentiment analysis,or text dataset.but NOT sutabile for highly\n",
        "correlated data .\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\"\"\"\n",
        "----------------------------------------------------------------------------------------------\n",
        "# k-nearest neighbor\n",
        " from sklearn.neighbors import KNeighborsClassifier\n",
        " model = KNeighborsClassifier(n_neighbors=3)\n",
        " model.fit(x,y)\n",
        " print (model.predict())\n",
        "-----------------------------------------------------------------------------------------------\n",
        "# support vector machine(svm)\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "iris= datasets.load_iris()\n",
        "x =iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3)\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(x_train,y_train)\n",
        "y_pred= model.predict(x_test)\n",
        "print (y_pred)\n",
        "-------------------------------------------------------------------------------------------------\n",
        "# random forest\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "iris= datasets.load_iris()\n",
        "x =iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3)\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred= model.predict(x_test)\n",
        "print (y_pred)\n",
        "------------------------------------------------------------------------------------------\n",
        "# decision tree\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "iris= datasets.load_iris()\n",
        "x =iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3)\n",
        "model = DecisionTreeClassifier(criterion='gini', max_depth=0.3)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred= model.predict(x_test)\n",
        "print (y_pred)\n",
        "---------------------------------------------------------------------------------------------\n",
        "# LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "iris= datasets.load_iris()\n",
        "x =iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3)\n",
        "model =LogisticRegression(max_iter=1000)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred= model.predict(x_test)\n",
        "print (y_pred)\n",
        "-----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest algorithm supervised algoritm in regression\n",
        "\"\"\"\n",
        "it can use for classification and regression tasks.the purpose of the forest algorithm is to create a powerfull,accurate, robust\n",
        " prediction model by combining the many dicision tree.improve accuract, reduce overfitting,handling missing values, work\n",
        " with high dimension data,\n",
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load example dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "-------------------------------------------------------------------------------------------\n",
        "# decision tree\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "iris= datasets.load_iris()\n",
        "x =iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3)\n",
        "model = DecisionTreeClassifier(criterion='gini', max_depth=0.3)\n",
        "model.fit(x_train,y_train)\n",
        "y_pred= model.predict(x_test)\n",
        "print (y_pred)\n",
        "-------------------------------------------------------------------------------------\n",
        "#ridge/lasso regression\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Generate regression data\n",
        "X, y = make_regression(n_samples=100, n_features=10, noise=15, random_state=42)\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "# Ridge Regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_preds = ridge.predict(X_test)\n",
        "# Lasso Regression\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "lasso_preds = lasso.predict(X_test)\n",
        "# Evaluation\n",
        "print(\"Ridge MSE:\", mean_squared_error(y_test, ridge_preds))\n",
        "print(\"Lasso MSE:\", mean_squared_error(y_test, lasso_preds))\n",
        "\n"
      ],
      "metadata": {
        "id": "y61uvvTpnnyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA(linear discriminant analysis) dimensionality reduction\n",
        "\"\"\"\n",
        "lda is supervise machine learning algoritm used for clssificatin and dimensionlity reduction. mian goal to find best\n",
        "seperation between different classes\n",
        "\"\"\"\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load data\n",
        "X, y = load_iris(return_X_y=True)\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Train LDA\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "# Predict\n",
        "y_pred = lda.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# PCA\n",
        "# T-SNE\n"
      ],
      "metadata": {
        "id": "_oDesoA_nvgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOSS FUNCTIONS\n",
        "# 1. lOG loss metrics\n",
        "\"\"\"\n",
        "also clled cross-entropy measure the performance of classification model when output is probability value between 0 to 1\n",
        ".it penalized(panisment dega ) incorrect predictions especially when the predicted probility is far fromthe actual class\n",
        "lower log loss == better model (work for both binary class and multi class classification)\n",
        "\"\"\"\n",
        "form sklearn.metrics import log_loss\n",
        "y_test=[1,0,1]\n",
        "y_pred=[0.9,0.2,0.8]\n",
        "loss = log_loss(y_test,y_pred)\n",
        "print (loss)\n",
        "\n",
        "# 2. r-squared(r^2)\n",
        "\"\"\"\n",
        "also called the coefficient of determination- measure how well a regression model explains the variance  of\n",
        "target variable.but dosent measure model bias and overfitteng,not idal for non linear model\n",
        "\"\"\"\n",
        "form sklearn.metrics import r2_score\n",
        "y_test=[1,0,1]\n",
        "y_pred=[0.9,0.2,0.8]\n",
        "loss = r2_score(y_test,y_pred)\n",
        "print (loss)\n",
        "\n",
        "# 3. gini index\n",
        "\"\"\"\n",
        "gini index is matrics used to measure the purity of data set at a particular node in a decision tree.gini=o perfect pure\n",
        "(all semple belong to one class), higher gini = more mixed class (less pure). the gole is minimize the gini index\n",
        "\"\"\"\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Build decision tree using Gini (default)\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
        "clf.fit(X_train, y_train)\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "OMG44Yc6i7BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "jnRRZ1ZXjTxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}