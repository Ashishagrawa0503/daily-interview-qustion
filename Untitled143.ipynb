{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZWmOvzccka9s6mRz3tWHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishagrawa0503/daily-interview-qustion/blob/main/Untitled143.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_6nNRiGovis"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "POS tagging- Part of Speech Tagging\n",
        "--POS Tagging मतलब है किसी sentence में हर word का grammatical label (जैसे noun, verb, adjective) assign करना।\n",
        "POS tagging का मतलब है — हर word को उसकी role के हिसाब से पहचानना कि वो क्या है: संज्ञा (noun), क्रिया (verb), विशेषण (adjective) आदि\n",
        "Ex- Ravi is playing cricket in the park. Isme ravi noun hai playing verb hai ect\n",
        "Use for machine translation ,nlp models\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "meta-learning-\n",
        "Meta-learning एक ऐसा system है जो ये नहीं सीखता कि “क्या करना है”, बल्कि ये सीखता है कि “कैसे सीखना है”\n",
        "नए tasks को कम examples में जल्दी सीख पाना।\n",
        "model based meta learning-lstm based meta learner\n",
        "metric based meta learning-\n",
        "1.siamese network-Siameseq Network दो inputs को एक साथ देखता है, और यह decide करता है कि दोनों एक जैसे हैं या नहीं।\n",
        "A Siamese Network is a neural network architecture that learns similarity between two inputs instead of just classifying them.\n",
        "It’s very useful for tasks like:Face recognition,Signature verification,One-shot / Few-shot learning\n",
        "2.prototypical network-ye few short learning ko support kta hai. har class ka proto type bnata hai or nye input ko us proto type\n",
        "se distance find karke clssifi krta hai.\n",
        "optimization based meta learnig-MAML(model agnostic meta learnig)(maml main model aase train kiya jata hai ke wo new task ko\n",
        " srif kuch gradient step main slove kar le)\n",
        " application - reinforcment learning, auto ml, few short learning\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "contrastive learning--\n",
        "Contrastive Learning एक ऐसा technique है जहां model ये सीखता है कि क्या similar है और क्या different।\n",
        "यह unsupervised/self-supervised learning का हिस्सा है और modern deep learning में बहुत powerful साबित हुआ है — खासकर\n",
        "representation learning में।\n",
        "Contrastive learning model को यह सिखाता है कि —एक जैसे चीज़ों को करीब लाओ,और अलग-अलग चीज़ों को दूर रखो embedding space में।\n",
        "(SSL-Self-Supervised Learning (SSL) एक ऐसा machine learning तरीका है जिसमें model labels खुद generate करता है, और खुद से सीखता है —\n",
        " बिना manually labeled data के common domain where ssl is used bert,gpt,simCLR,MoCo)\n",
        " loss function - contrastive loss, NT-XENT loss,\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "stochastic gradient descent-(SGD)-\n",
        "-SGD is the most common algorithm used to train deep learning models. It’s a faster and more memory-efficient version\n",
        " of gradient descent.\n",
        "Stochastic Gradient Descent (SGD) एक ऐसा तरीका है जो model को धीरे-धीरे सुधारता है — हर बार data का एक छोटा हिस्सा (या एक sample)\n",
        "देखकर। ❞यानी: हर बार पूरा dataset देखने की ज़रूरत नहीं, बस एक या कुछ examples देखकर ही model update होता है।memory sificent,\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "GRADIENT CLIPPING-Gradient Clipping एक technique है जिसे हम deep learning में use करते हैं ताकि gradients बहुत ज़्यादा बड़े न\n",
        "हो जाएँ और model unstable न हो जाए।\n",
        "जब training के दौरान gradients बहुत बड़े हो जाते हैं, तो model weights अचानक कूद सकते हैं और training खराब हो सकती है।\n",
        "Gradient Clipping एक “limit” लगाता है कि gradients कितने बड़े हो सकते हैं\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "WEIGHT DECAY-YE REGULARIZATION TECHNIQUE HAI JO DEEPLEARNING model ko overfitting se bachata hai  ye baata hai ke bade bade\n",
        "wight naa rakhke. bade wight ko dheere dheere chota krte rahe take model simple or unseen data par accha perform kar sake\n",
        "l1,l2 are common wihght decay\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "j4oxD-YDvAwt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}